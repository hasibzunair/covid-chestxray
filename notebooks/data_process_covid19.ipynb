{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download from https://github.com/ieee8023/covid-chestxray-dataset\n",
    "\n",
    "Make a folder named covid and put the images and metadata.csv files in it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from skimage.transform import resize\n",
    "from skimage import io\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "\n",
    "sys.path.append(ROOT_DIR)  \n",
    "import helpers\n",
    "\n",
    "\n",
    "DATASET_NAME = \"covid\"\n",
    "DATA_PATH = os.path.join(ROOT_DIR, \"dataset\")\n",
    "COVID_DATASET_PATH = os.path.join(DATA_PATH, DATASET_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = pd.read_csv(os.path.join(COVID_DATASET_PATH, 'metadata.csv'))\n",
    "dt = dt[[\"finding\", \"view\", \"modality\", \"filename\"]].dropna()\n",
    "# Remove all CTs\n",
    "dt = dt[dt.modality != \"CT\"]\n",
    "# Only samples with COVID-19\n",
    "dt = dt[dt.finding == \"COVID-19\"]\n",
    "\n",
    "dt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels\n",
    "labels = dt[[\"finding\"]].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = dt[\"filename\"].values\n",
    "image_path[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dir\n",
    "train_covid_images = os.path.join(DATA_PATH, \"cxr\", \"train\", \"cov19\")\n",
    "test_covid_images = os.path.join(DATA_PATH, \"cxr\", \"test\", \"cov19\")\n",
    "\n",
    "helpers.create_directory(train_covid_images)\n",
    "helpers.create_directory(test_covid_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# slicing index should be the minmum number across all the dataset classes\n",
    "\n",
    "tr_imgs = [os.path.join(COVID_DATASET_PATH, \"images\", x) for x in image_path[:180]]\n",
    "test_imgs = [os.path.join(COVID_DATASET_PATH, \"images\", x) for x in image_path[180:]]\n",
    "\n",
    "len(tr_imgs), len(test_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "for file in tr_imgs:\n",
    "    shutil.copy(file, train_covid_images)\n",
    "    \n",
    "for file in test_imgs:\n",
    "    shutil.copy(file, test_covid_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COVID: 226 -> 180 + 46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classes for data loading and preprocessing\n",
    "class COVIDChestXRayDataset:\n",
    "    def __init__(\n",
    "            self,\n",
    "            datadir,\n",
    "            csv_path,\n",
    "            flag,\n",
    "    ):\n",
    "        \n",
    "        # Patient names in folder\n",
    "        #self.ids = sorted(os.listdir(datadir))\n",
    "        # Sorted patient names in folder\n",
    "        #self.images_fps = [os.path.join(datadir, image_id) for image_id in self.ids]\n",
    "        \n",
    "\n",
    "        # Read csv path\n",
    "        csv = pd.read_csv(os.path.join(csv_path))\n",
    "        csv = csv[[\"survival\", \"modality\", \"filename\"]].dropna()\n",
    "        csv = csv[csv.modality != \"CT\"]\n",
    "        \n",
    "        # Image names\n",
    "        self.image_names = csv[\"filename\"].values\n",
    "        \n",
    "        \n",
    "        # Get labels\n",
    "        self.labels = csv[[\"survival\"]].values\n",
    "        self.image_paths = [os.path.join(datadir, image_id) for image_id in self.image_names]\n",
    "        \n",
    "        # Split\n",
    "        train_vols, test_vols, train_labels, test_labels = train_test_split(self.image_paths, self.labels, test_size=0.20, random_state=42)\n",
    "        print(len(train_vols), len(test_vols))\n",
    "        \n",
    "        self.train_vols = train_vols\n",
    "        self.test_vols = test_vols\n",
    "        self.train_labels = train_labels\n",
    "        self.test_labels = test_labels\n",
    "        \n",
    "        if flag == \"train\":\n",
    "            self.image_paths = self.train_vols\n",
    "            self.labels = self.train_labels\n",
    "            self.ids = self.train_vols\n",
    "            \n",
    "        else:\n",
    "            self.image_paths = self.test_vols\n",
    "            self.labels = self.test_labels\n",
    "            self.ids = self.test_vols\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # Read data\n",
    "        img = io.imread(self.image_paths[i])\n",
    "        img = resize(img, (256, 256))\n",
    "        \n",
    "        img = img.astype(np.float32)\n",
    "        img /= 255\n",
    "        \n",
    "        # Taken from https://github.com/mlmed/torchxrayvision/blob/master/torchxrayvision/datasets.py#L814\n",
    "        # Check that images are 2D arrays\n",
    "        if len(img.shape) > 2:\n",
    "            img = img[:, :, 0]\n",
    "        if len(img.shape) < 2:\n",
    "            print(\"error, dimension lower than 2 for image\")\n",
    "\n",
    "        # Add color channel\n",
    "        img = img[:, :, None]\n",
    "        \n",
    "        # Get labels\n",
    "        gt = self.labels[i]\n",
    "        if gt == \"Y\":\n",
    "            gt = 1 # Survival: Yes\n",
    "        else:\n",
    "            gt = 0 # Survial: No\n",
    "            \n",
    "        gt = keras.utils.to_categorical(gt, 2)\n",
    "        \n",
    "        return img, gt\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataloder(keras.utils.Sequence):\n",
    "    \"\"\"Load data from dataset and form batches\n",
    "    \n",
    "    Args:\n",
    "        dataset: instance of Dataset class for image loading and preprocessing.\n",
    "        batch_size: Integet number of images in batch.\n",
    "        shuffle: Boolean, if `True` shuffle image indexes each epoch.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, dataset, batch_size=1, shuffle=False):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.indexes = np.arange(len(dataset))\n",
    "\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        # collect batch data\n",
    "        start = i * self.batch_size\n",
    "        stop = (i + 1) * self.batch_size\n",
    "        data = []\n",
    "        for j in range(start, stop):\n",
    "            data.append(self.dataset[j])\n",
    "        \n",
    "        # Transpose list of lists\n",
    "        batch = [np.stack(samples, axis=0) for samples in zip(*data)]\n",
    "        \n",
    "        return batch\n",
    "    \n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the number of batches per epoch\"\"\"\n",
    "        return len(self.indexes) // self.batch_size\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        \"\"\"Callback function to shuffle indexes each epoch\"\"\"\n",
    "        if self.shuffle:\n",
    "            self.indexes = np.random.permutation(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CSV_PATH = os.path.join(DATASET_PATH, \"metadata.csv\")\n",
    "CSV_PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# image path, csv path\n",
    "train_dataset = COVIDChestXRayDataset(IMAGES_PATH, CSV_PATH, flag=\"train\")\n",
    "test_dataset = COVIDChestXRayDataset(IMAGES_PATH, CSV_PATH, flag=\"test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, gt = train_dataset[0] \n",
    "image.shape, gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.squeeze(image)\n",
    "plt.imshow(image, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = Dataloder(train_dataset, batch_size=1, shuffle=True)\n",
    "test_dataloader = Dataloder(test_dataset, batch_size=1, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(train_dataloader), len(test_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (features, targets) in enumerate(train_dataloader):\n",
    "    print(batch_idx, features.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for batch_idx, (features, targets) in enumerate(test_dataloader):\n",
    "    print(batch_idx, features.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks for learning rate scheduling, logging and best checkpoints saving\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('{}/{}.h5'.format(LOG_PATH, EXPERIMENT_NAME), monitor='val_loss', save_best_only=True, mode='min'),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, verbose=1, patience=5, mode='min'), ## new_lr = lr * factor # 5\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, verbose=1, patience=15, mode='min', restore_best_weights=True), # 8\n",
    "    keras.callbacks.CSVLogger('{}/training.csv'.format(LOG_PATH))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "start_time = time.time()\n",
    "\n",
    "\n",
    "history = model.fit_generator(\n",
    "    train_dataloader, \n",
    "    steps_per_epoch=len(train_dataloader), \n",
    "    epochs=EPOCHS, \n",
    "    callbacks=callbacks, \n",
    "    validation_data=valid_dataloader, \n",
    "    validation_steps=len(valid_dataloader),  # val samples = batch size * no of steps\n",
    ")\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time)//3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
