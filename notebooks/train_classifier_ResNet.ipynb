{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import scipy.misc\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "import random \n",
    "import shutil \n",
    "import keras\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.layers import Dense, Input, Conv2D, Flatten, MaxPool2D, Activation,Dropout, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import backend as K\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.applications.resnet import ResNet50\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam\n",
    "from keras import optimizers\n",
    "import pickle\n",
    "\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "\n",
    "sys.path.append(ROOT_DIR)\n",
    "import helpers\n",
    "\n",
    "data_name = \"cxr_normalvg1\" \n",
    "DATASET_PATH = os.path.join(ROOT_DIR, \"dataset\", data_name ,\"train\")\n",
    "TEST_DATASET_PATH = os.path.join(ROOT_DIR, \"dataset\", data_name ,\"test\")\n",
    "EXPERIMENT_NAME = data_name #\"cxr_normalvcovid+g1g2_new\"\n",
    "\n",
    "if not os.path.exists(os.path.join(ROOT_DIR, \"models\")):\n",
    "    os.mkdir(os.path.join(ROOT_DIR, \"models\"))\n",
    "\n",
    "LOG_PATH = os.path.join(ROOT_DIR, \"models\", EXPERIMENT_NAME)\n",
    "\n",
    "if not os.path.exists(LOG_PATH):\n",
    "    os.mkdir(LOG_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helpers\n",
    "def save_obj(obj, name):\n",
    "    with open('{}'.format(LOG_PATH) + \"/\"+ name + '.pkl', 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_obj(name):\n",
    "    with open('{}'.format(LOG_PATH) + name + '.pkl', 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "def resnet50():\n",
    "    base_model = ResNet50(weights='imagenet',include_top=False,pooling='avg',input_shape=(256, 256, 3))\n",
    "    # Add FC layer\n",
    "    predictions = Dense(2, activation='softmax', trainable=True)(base_model.output) \n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable=True\n",
    "        \n",
    "    model = Model(inputs=[base_model.input], outputs=[predictions])\n",
    "        \n",
    "    # Optimzer and loss\n",
    "    optim = optimizers.Adadelta(lr=0.001) #Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    loss_func = 'binary_crossentropy' \n",
    "    \n",
    "    model.compile(optimizer=optim, loss=loss_func, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "def vgg():\n",
    "    base_model = VGG16(weights='imagenet',include_top=False,pooling='avg',input_shape=(256, 256, 3))\n",
    "    # Add FC layer\n",
    "    predictions = Dense(2, activation='softmax', trainable=True)(base_model.output) \n",
    "    \n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable=True\n",
    "        \n",
    "    model = Model(inputs=[base_model.input], outputs=[predictions])\n",
    "        \n",
    "    # Optimzer and loss\n",
    "    optim = optimizers.Adadelta(lr=0.001) #Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "    loss_func = 'binary_crossentropy' \n",
    "    \n",
    "    model.compile(optimizer=optim, loss=loss_func, metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "model = None\n",
    "model = vgg()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define callbacks for learning rate scheduling, logging and best checkpoints saving\n",
    "callbacks = [\n",
    "    keras.callbacks.ModelCheckpoint('{}/{}.h5'.format(LOG_PATH, EXPERIMENT_NAME), monitor='val_loss', save_best_only=True, mode='min'),\n",
    "    keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, verbose=1, patience=5, mode='min'), ## new_lr = lr * factor # 5\n",
    "    keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0, verbose=1, patience=15, mode='min', restore_best_weights=True), # 8\n",
    "    keras.callbacks.CSVLogger('{}/training.csv'.format(LOG_PATH))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import keras_preprocessing\n",
    "from keras_preprocessing import image\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "\n",
    "\n",
    "#---------------------------\n",
    "# cxr\n",
    "# 0 - cov\n",
    "# 1 - normal\n",
    "# 2 - pneu\n",
    "#---------------------------\n",
    "# cxr_normalvcovid\n",
    "# 0 - cov19\n",
    "# 1 - normal\n",
    "#---------------------------\n",
    "# cxr_pneucovid\n",
    "# 0 - cov19\n",
    "# 1 - pneu\n",
    "#---------------------------\n",
    "#class_weight = {0: 0.9, 1: 0.1}\n",
    "\n",
    "def processing_func(img):\n",
    "    # do sth\n",
    "    \n",
    "    \n",
    "    return img\n",
    "\n",
    "\n",
    "# preprocessing_function=None\n",
    "\n",
    "TRAINING_DIR = DATASET_PATH\n",
    "training_datagen = ImageDataGenerator(\n",
    "        rescale = 1./255)\n",
    "        #rotation_range=40,\n",
    "        #width_shift_range=0.2,\n",
    "        #height_shift_range=0.2,\n",
    "        #shear_range=0.2,\n",
    "        #zoom_range=0.2,\n",
    "        #horizontal_flip=True,\n",
    "        #fill_mode='nearest')\n",
    "\n",
    "VALIDATION_DIR = TEST_DATASET_PATH\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = training_datagen.flow_from_directory(\n",
    "    TRAINING_DIR,\n",
    "    target_size=(256,256),\n",
    "    class_mode='categorical',\n",
    "    batch_size = 16\n",
    ")\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "    VALIDATION_DIR,\n",
    "    target_size=(256,256),\n",
    "    class_mode='categorical',\n",
    "    batch_size = 16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_generator))\n",
    "x.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(x[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "\n",
    "history = model.fit_generator(train_generator, \n",
    "                    epochs=200, validation_data = validation_generator, \n",
    "                    verbose = 1,\n",
    "                    class_weight=None,\n",
    "                    callbacks=callbacks, shuffle=True)\n",
    "\n",
    "\n",
    "end_time = time.time()\n",
    "print(\"--- Time taken to train : %s hours ---\" % ((end_time - start_time)//3600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot and save accuravy loss graphs individually\n",
    "def plot_loss_accu(history):\n",
    "    loss = history.history['loss']\n",
    "    val_loss = history.history['val_loss']\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'g')\n",
    "    plt.plot(epochs, val_loss, 'y')\n",
    "    #plt.title('Training and validation loss')\n",
    "    plt.ylabel('Loss %')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper right')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('{}/{}_loss.jpg'.format(LOG_PATH, EXPERIMENT_NAME), dpi=100)\n",
    "    plt.show()\n",
    "    \n",
    "    loss = history.history['accuracy']\n",
    "    val_loss = history.history['val_accuracy']\n",
    "    epochs = range(len(loss))\n",
    "    plt.plot(epochs, loss, 'r')\n",
    "    plt.plot(epochs, val_loss, 'b')\n",
    "    #plt.title('Training and validation accuracy')\n",
    "    plt.ylabel('Accuracy %')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'val'], loc='lower right')\n",
    "    plt.grid(True)\n",
    "    plt.savefig('{}/{}_acc.jpg'.format(LOG_PATH, EXPERIMENT_NAME), dpi=100)\n",
    "    plt.show()\n",
    "\n",
    "plot_loss_accu(history)\n",
    "print(\"Done training and logging!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "\n",
    "model = None\n",
    "model = load_model(\"{}/{}.h5\".format(LOG_PATH, EXPERIMENT_NAME), compile = False)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get test data\n",
    "\n",
    "#---------------------------\n",
    "# cxr\n",
    "# 0 - cov\n",
    "# 1 - normal\n",
    "# 2 - pneu\n",
    "# test_all\n",
    "#---------------------------\n",
    "# cxr_normalvcovid\n",
    "# 0 - cov19\n",
    "# 1 - normal\n",
    "#test_nvc\n",
    "#---------------------------\n",
    "# cxr_pneucovid\n",
    "# 0 - cov19\n",
    "# 1 - pneu\n",
    "# test_pvc\n",
    "#---------------------------\n",
    "\n",
    "\n",
    "dest_path = os.path.join(ROOT_DIR, \"dataset/numpy/\")\n",
    "\n",
    "x_test = np.load(\"{}/test_nvc.npy\".format(dest_path))\n",
    "y_test = np.load(\"{}/test_nvc_labels.npy\".format(dest_path))\n",
    "x_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\n",
    "x_test = x_test.astype('float32')\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions using trained model\n",
    "y_pred = model.predict(x_test, verbose=1)\n",
    "print(\"Predictions: \", y_pred.shape)\n",
    "\n",
    "\n",
    "y_pred_inv = []\n",
    "\n",
    "for y in y_pred:\n",
    "    y = np.flip(y, 0 )\n",
    "    y_pred_inv.append(y)\n",
    "\n",
    "y_pred = np.array(y_pred_inv)\n",
    "print(\"New: \", y_pred.shape)\n",
    "\n",
    "\n",
    "# GTs\n",
    "#y_test_flat = y_test\n",
    "\n",
    "#y_pred_flat = []\n",
    "#for pred in y_pred:\n",
    "#    if pred > 0.5:\n",
    "#        y_pred_flat.append(1)\n",
    "#    else:\n",
    "#        y_pred_flat.append(0)\n",
    "#y_pred_flat = np.array(y_pred_flat)\n",
    "\n",
    "\n",
    "# Convert ground truth to column values\n",
    "y_test_flat = np.argmax(y_test, axis=1)\n",
    "print(\"After flattening ground truth: \", y_test_flat.shape)\n",
    "\n",
    "\n",
    "# Get labels from predictions\n",
    "y_pred_flat = np.array([np.argmax(pred) for pred in y_pred]) \n",
    "print(\"Binarize probability values: \", y_pred_flat.shape)\n",
    "\n",
    "assert y_pred_flat.shape == y_test_flat.shape, \"Shape mismatch!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sanity check\n",
    "\n",
    "print(y_test.shape, y_test_flat.shape, y_pred.shape, y_pred_flat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_flat_ = []\n",
    "\n",
    "for y in y_test_flat:\n",
    "    if y==0:\n",
    "        y_test_flat_.append(1)\n",
    "    else:\n",
    "        y_test_flat_.append(0)\n",
    "        \n",
    "        \n",
    "#y_pred_flat_ = []\n",
    "\n",
    "#for y in y_pred_flat:\n",
    "#    if y==0:\n",
    "#        y_pred_flat_.append(1)\n",
    "#    else:\n",
    "#        y_pred_flat_.append(0)\n",
    "        \n",
    "        \n",
    "y_test_flat = np.array(y_test_flat_)\n",
    "#y_pred_flat = np.array(y_pred_flat_)\n",
    "\n",
    "print(y_test_flat.shape, y_pred_flat.shape)\n",
    "\n",
    "y_test = keras.utils.to_categorical(y_test_flat, 2)\n",
    "#y_pred = keras.utils.to_categorical(y_pred_flat, 2)\n",
    "print(y_test.shape, y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals = []\n",
    "\n",
    "for yhat, y in zip(y_pred_inv, y_test):\n",
    "    if y[1] == 1:\n",
    "        vals.append(yhat[1])\n",
    "    \n",
    "vals = np.array(vals)\n",
    "vals.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = [i for i in range(46)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(vals, bins=46, color='c')\n",
    "x = vals\n",
    "plt.scatter(y, x)\n",
    "#plt.title(\"Confidence of COVID-19 on NVC + G2 + G1\")\n",
    "plt.xlabel(\"Number of COVID cases\")\n",
    "#plt.grid(True)\n",
    "plt.ylabel(\"Probability\")\n",
    "plt.savefig(\"{}/{}.pdf\".format(LOG_PATH, EXPERIMENT_NAME), dpi=100)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.count_nonzero(y_test_flat == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Accuracy\n",
    "acc = accuracy_score(y_test_flat, y_pred_flat) * 100\n",
    "print(\"Accuracy :\", acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Classification report\n",
    "\n",
    "confusion_mtx = confusion_matrix(y_test_flat, y_pred_flat) \n",
    "print(confusion_mtx)\n",
    "target_names = ['0', '1']\n",
    "print(classification_report(y_test_flat, y_pred_flat, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tn, fp, fn, tp = confusion_matrix(y_test_flat, y_pred_flat).ravel()\n",
    "tn, fp, fn, tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity = tp /(tp + fn)\n",
    "sensitivity * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp+fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kappa\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "\n",
    "kp = cohen_kappa_score(y_test_flat, y_pred_flat)\n",
    "print(\"Kappa :\", kp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import brier_score_loss\n",
    "\n",
    "br = brier_score_loss(y_test_flat, y_pred_flat, pos_label=1)\n",
    "print(\"Brier loss :\", br)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.0088\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Average precision\n",
    "\n",
    "from sklearn.metrics import average_precision_score\n",
    "ap = average_precision_score(y_test, y_pred) * 100\n",
    "print(\"Average precision :\", ap)\n",
    "\n",
    "# 75.81,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sensitivity and Specificity\n",
    "\n",
    "#cm = confusion_matrix(y_pred=y_pred_flat, y_true=y_test_flat)\n",
    "#total=sum(sum(cm))\n",
    "\n",
    "##sensitivity = cm[0,0]/(cm[0,0]+cm[1,0])\n",
    "#print('Sensitivity : ', sensitivity*100 )\n",
    "\n",
    "#Specificity = cm[1,1]/(cm[1,1]+cm[0,1])\n",
    "#print('Specificity : ', Specificity*100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "print('Area under ROC curve : ', roc_auc_score(y_test, y_pred) *100 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "F1_score = f1_score(y_test_flat, y_pred_flat, labels=None, average='binary', sample_weight=None)\n",
    "F1_score * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, precision_recall_curve\n",
    "\n",
    "# PR curve\n",
    "y_true = y_test.ravel() \n",
    "y_preds = y_pred.ravel() \n",
    "precision, recall, thresholds = precision_recall_curve(y_true, y_preds)\n",
    "plt.figure(20)\n",
    "plt.plot(recall,precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ascore = {}\n",
    "ascore[\"recall\"] = recall\n",
    "ascore[\"precision\"] = precision\n",
    "save_obj(ascore, \"{}_PR_curve\".format(data_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from itertools import cycle\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "\n",
    "\n",
    "# Compute ROC curve and ROC area for each class\n",
    "fpr = dict()\n",
    "tpr = dict()\n",
    "roc_auc = dict()\n",
    "for i in range(2):\n",
    "    fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n",
    "    roc_auc[i] = auc(fpr[i], tpr[i])\n",
    "\n",
    "\n",
    "# Compute micro-average ROC curve and ROC area\n",
    "cls = 1 # class name\n",
    "fpr[\"micro\"], tpr[\"micro\"], _ = roc_curve(y_test.ravel(), y_pred.ravel())\n",
    "roc_auc[\"micro\"] = auc(fpr[\"micro\"], tpr[\"micro\"])\n",
    "\n",
    "#print(roc_auc)\n",
    "print(\"Area under the ROC curve for positive class:\", roc_auc[1])\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "lw = 2 # line width\n",
    "plt.plot(fpr[cls], tpr[cls], color='darkorange', lw=lw, label='ROC curve (area = %0.2f)' % roc_auc[cls])\n",
    "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver operating characteristic example')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n",
    "\n",
    "# Save AUCROC for plotting\n",
    "ascore = {}\n",
    "ascore[\"fpr\"] = fpr[cls]\n",
    "ascore[\"tpr\"] = tpr[cls]\n",
    "ascore[\"roc_auc\"] = roc_auc[cls]\n",
    "save_obj(ascore, data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
